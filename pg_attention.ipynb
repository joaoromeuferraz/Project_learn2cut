{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 17:05:42.665148: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 17:05:44.444292: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-12-12 17:05:44.444531: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-12-12 17:05:44.444545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjrferraz\u001b[0m (\u001b[33morcs4529\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/Project_learn2cut/wandb/run-20221212_170547-pwnylh0p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/orcs4529/finalproject/runs/pwnylh0p\" target=\"_blank\">earthy-dust-2204</a></strong> to <a href=\"https://wandb.ai/orcs4529/finalproject\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymenv_v2\n",
    "from gymenv_v2 import make_multiple_env\n",
    "import numpy as np\n",
    "from config import custom_config, easy_config, hard_config\n",
    "from layers import Embedding\n",
    "import tensorflow as tf\n",
    "from policy import Policy\n",
    "from rollout import rollout, rollout_envs\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "run=wandb.init(project=\"finalproject\", entity=\"orcs4529\", tags=[\"training-easy\"])\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training instances, dir instances/train_10_n60_m60 idx 0\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 1\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 2\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 3\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 4\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 5\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 6\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 7\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 8\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 9\n"
     ]
    }
   ],
   "source": [
    "env = make_multiple_env(**easy_config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"results\"):\n",
    "    os.mkdir(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [64, 64]\n",
    "activations = ['tanh', 'tanh']\n",
    "lr = 0.01  ### CHANGE\n",
    "num_episodes = 200\n",
    "num_trajectories = 10 ### CHANGE\n",
    "delta_std = 0.1\n",
    "rollout_length = 1\n",
    "time_limit = 50 ### CHANGE\n",
    "gamma = 0.90\n",
    "\n",
    "run_name = \"easy_baseline2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"results/{run_name}\"):\n",
    "    os.mkdir(f\"results/{run_name}\")\n",
    "\n",
    "all_params = {\n",
    "    \"units\": units, \"activations\": activations, \"lr\": lr, \"num_episodes\": num_episodes,\n",
    "    \"num_trajectories\": num_trajectories, \"delta_std\": delta_std, \"rollout_length\": rollout_length,\n",
    "    \"time_limit\": time_limit, \"gamma\": gamma\n",
    "}\n",
    "np.save(f\"results/{run_name}/params\", all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running loop over episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2024-10-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 17:06:05.505348: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-12-12 17:06:05.505621: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-12 17:06:05.505708: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (learn2cut): /proc/driver/nvidia/version does not exist\n",
      "2022-12-12 17:06:05.506963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# initialize policy and test\n",
    "policy = Policy(units, activations)\n",
    "s = env.reset()\n",
    "_ = policy.compute_prob(s)\n",
    "rewards_record = []\n",
    "\n",
    "for e in range(num_episodes):\n",
    "    w_orig_cons, w_orig_cuts = policy.get_weights()\n",
    "    epsilon_table_cons, epsilon_table_cuts = [], []\n",
    "    train_rewards_table = []\n",
    "    for t in range(num_trajectories):\n",
    "        epsilon_cons = [np.random.randn(*x.shape)*delta_std for x in w_orig_cons]\n",
    "        epsilon_cuts = [np.random.randn(*x.shape)*delta_std for x in w_orig_cuts]\n",
    "        w_new_cons = [w_orig_cons[i] + epsilon_cons[i] for i in range(len(w_orig_cons))]\n",
    "        w_new_cuts = [w_orig_cuts[i] + epsilon_cuts[i] for i in range(len(w_orig_cuts))]\n",
    "        policy.set_weights(w_new_cons, w_new_cuts)\n",
    "        rewards, times = rollout_envs(envs=env.envs, policy=policy, num_rollouts=1, rollout_length=rollout_length, gamma=gamma)\n",
    "        epsilon_table_cons.append(epsilon_cons)\n",
    "        epsilon_table_cuts.append(epsilon_cuts)\n",
    "        # epsilon_table.append(epsilon)\n",
    "        train_rewards_table.append(np.mean(rewards))\n",
    "    \n",
    "    train_rewards_table = np.array(train_rewards_table)\n",
    "    train_rewards_table = (train_rewards_table - np.mean(train_rewards_table))/ (np.std(train_rewards_table) + 1e-8)\n",
    "\n",
    "    grads_cons = []\n",
    "    grads_cuts = []\n",
    "    for j in range(len(w_orig_cons)):\n",
    "        arr_cons = np.zeros(epsilon_table_cons[0][j].shape)\n",
    "        arr_cuts = np.zeros(epsilon_table_cuts[0][j].shape)\n",
    "        for i in range(len(epsilon_table_cons)):\n",
    "            arr_cons += epsilon_table_cons[i][j] * train_rewards_table[i]\n",
    "            arr_cuts += epsilon_table_cuts[i][j] * train_rewards_table[i]\n",
    "        arr_cons /= (len(epsilon_table_cons) * delta_std)\n",
    "        arr_cuts /= (len(epsilon_table_cuts) * delta_std)\n",
    "        grads_cons.append(arr_cons)\n",
    "        grads_cuts.append(arr_cuts)\n",
    "    \n",
    "    # assign back original weights and update\n",
    "    w_cons = [w_orig_cons[i] - lr*grads_cons[i] for i in range(len(w_orig_cons))]\n",
    "    w_cuts = [w_orig_cuts[i] - lr*grads_cuts[i] for i in range(len(w_orig_cuts))]\n",
    "\n",
    "    policy.set_weights(w_cons, w_cuts)\n",
    "    \n",
    "    # evaluate rewards\n",
    "    eval_r, _ = rollout_envs(envs=env.envs, policy=policy, num_rollouts=1, rollout_length=time_limit, gamma=gamma)\n",
    "    print(f\"Episode {e}:\")\n",
    "    print('mean',np.mean(eval_r),'max',np.max(eval_r),'min',np.min(eval_r),'std',np.std(eval_r))\n",
    "    print(\"\")\n",
    "    rewards_record.append(np.mean(eval_r))\n",
    "    \n",
    "    fixedWindow = 100\n",
    "    movingAverage = 0\n",
    "    if len(rewards_record) >= fixedWindow:\n",
    "        movingAverage = np.mean(rewards_record[len(rewards_record)-fixedWindow:len(rewards_record)-1])\n",
    "        \n",
    "    wandb.log({\"Training reward\" : float(rewards_record[-1]), \"Training reward moving average\": movingAverage})\n",
    "    np.save(f\"results/{run_name}/reward{e}\", eval_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
